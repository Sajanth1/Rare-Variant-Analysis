# -*- coding: utf-8 -*-
"""VEP.SETID_prep.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1fxmN_JYOYuCZIAwJ1pzafCf0ilVGR3mg
"""

# Run from analysis

import pandas as pd
import numpy as np
import sys

cohort = sys.argv[1]

VEP_path = f"annotation/{cohort}.VEPannotated"

"""#Pre-Processing"""

# Remove metadata and read into pandas

with open(VEP_path, "r") as file:
    lines = file.readlines()

# Find the header line (first line starting with a single '#')
header_index = next(
    i
    for i, line in enumerate(lines)
    if line.startswith("#") and not line.startswith("##")
)

# Keep the header and all lines after it
cleaned_lines = lines[header_index:]

# Overwrite the original file with the cleaned content
with open(VEP_path, "w") as file:
    file.writelines(cleaned_lines)

VEP_df = pd.read_csv(VEP_path, sep="\t")

# Split Extra Column together-values into separate ones

cols = [
    "REF_ALLELE",
    "IMPACT",
    "SYMBOL",
    "HGVSc",
    "HGVSp",
    "gnomADg_AF",
    "gnomADg_ASJ_AF",
    "gnomADg_NFE_AF",
    "ClinVar_CLNSIG",
    "CADD_PHRED",
    "am_class",
    "am_pathogenicity",
]

# Note: Did not use CLIN_SIG value as this is the automatic one used by VEP based on ClinVar 202306. WHEREAS ClinVar_CLNSIG is based off
# local version "/lustre03/project/6004655/COMMUN/data/VEP/clinvar/clinvar_20240407.GRCh38.vcf.gz" (which is more comprehensive 1328(excluding ClinVar_CLNSIGCONF) vs. 1281)

# Step 1: Create empty lists to store the extracted values
split_cols = {i: [] for i in cols}

# Step 2: Iterate through each row in the 'Extra' column
for extra in VEP_df["Extra"]:

    # Split the 'Extra' column into individual key-value pairs
    key_value_pairs = extra.split(";")

    # Initialize variables to store the extracted values for this row (to not miss rows)
    extracted_values = {i: None for i in cols}

    # Iterate through each key-value pair
    for pair in key_value_pairs:
        if "=" in pair:  # Ensure the pair contains an '='
            key, value = pair.split("=", 1)
            if key in cols:
                extracted_values[key] = value  # Replace None by actual value

    # Append the extracted values to their respective lists
    for i in cols:
        split_cols[i].append(extracted_values[i])


# Step 3: Add the extracted values as new columns in the DataFrame
for i in cols:
    VEP_df[i] = split_cols[i]


# Reorder (also removes non-mentioned) & Rename columns

VEP_df = VEP_df.reindex(
    columns=[
        "#Uploaded_variation",
        "Location",
        "REF_ALLELE",
        "Allele",
        "Gene",
        "SYMBOL",
        "Feature",
        "Consequence",
        "IMPACT",
        "cDNA_position",
        "Protein_position",
        "Amino_acids",
        "Codons",
        "HGVSc",
        "HGVSp",
        "CADD_PHRED",
        "am_class",
        "am_pathogenicity",
        "ClinVar_CLNSIG",
        "gnomADg_AF",
        "gnomADg_ASJ_AF",
        "gnomADg_NFE_AF",
    ]
)

VEP_df.rename(
    columns={
        "#Uploaded_variation": "Tag",
        "REF_ALLELE": "Ref",
        "Allele": "Alt",
        "SYMBOL": "name",
        "ClinVar_CLNSIG": "ClinVar",
        "am_class": "AM_class",
        "am_pathogenicity": "AM_score",
    },
    inplace=True,
)

# Save
VEP_df.to_csv(f"annotation/{cohort}.VEPannotated_split.csv", sep="\t", index=False)


# Convert relevant columns to float (NaN-compatible) so that math-able
VEP_df["CADD_PHRED"] = VEP_df["CADD_PHRED"].replace([None], np.nan)
VEP_df["AM_score"] = VEP_df["AM_score"].replace([None], np.nan)

VEP_df["CADD_PHRED"] = VEP_df["CADD_PHRED"].astype(float)
VEP_df["AM_score"] = VEP_df["AM_score"].astype(float)


"""#Extract Groups"""

# all_df = VEP_df

# Filter for coding variants
exon_df = VEP_df[
    ~VEP_df["Consequence"].isin(
        [
            "intron_variant",
            "upstream_gene_variant",
            "downstream_gene_variant",
            "intergenic_variant",
        ]
    )
]

# # Filter for functional variants
# func_df = VEP_df[
#     (VEP_df["Consequence"].isin(["5_prime_UTR_variant", "3_prime_UTR_variant"])) |
#     (VEP_df["IMPACT"].isin(["HIGH", "MODERATE"]))
# ]

# Filter for nonsynonymous variants
nonsyn_df = VEP_df[VEP_df["Consequence"] == "missense_variant"]

# # Filter for pathogenic missense (nonsyn) via AlphaMissense
# am_df = VEP_df[VEP_df["AM_class"] == "likely_pathogenic"]

# Filter for CADD variants
cadd_df = VEP_df[VEP_df["CADD_PHRED"] >= 20]

# Filter for LOF variants (See VEP Consequence documenation, but basically: ablation, splice, stop, frameshift)
lof_df = VEP_df[VEP_df["IMPACT"] == "HIGH"]


"""USER INPUT"""

# Specify which sets to use
list_of_dfs = {
    "EXON": exon_df,
    "NONSYN": nonsyn_df,
    "CADD": cadd_df,
    "LOF": lof_df,
}


"""Remove Duplicates"""

dropped_counts = {}
for set_name, df in list_of_dfs.items():
    initial_count = len(df)
    list_of_dfs[set_name] = df.drop_duplicates(subset="Tag")
    final_count = len(list_of_dfs[set_name])
    dropped_counts[set_name] = initial_count - final_count

# Print the results
for set_name in list_of_dfs.keys():
    print(f"Duplicates removed from {set_name.lower()}_df: {dropped_counts[set_name]}")


"""#Make list of IDs for each gene"""

genelist = sys.argv[2:]

for gene in genelist:
    setid_filename = f"SKAT/{cohort}.{gene}.SETID"  # Create filename with gene name

    with open(setid_filename, "w") as output_file:
        for df_key, df_value in list_of_dfs.items():

            # Filter the DataFrame for the current gene && extract tags
            filtered_df = df_value[df_value["name"] == gene]
            rare_variants = filtered_df["Tag"]

            for variantID in rare_variants:
                output_file.write(f"{gene}_{df_key}\t{variantID}\t{gene}\t\n")
